name: Consolidate & Generate Captions

on:
  workflow_dispatch:   # or `push:`/`schedule:` if you prefer

jobs:
  consolidate_and_caption:
    runs-on: ubuntu-latest
    env:
      GH_TOKEN: ${{ secrets.GH_PAT }}    # PAT needed for gh api

    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Install GitHub CLI & jq
      run: sudo apt-get update && sudo apt-get install -y gh jq unzip

    - name: Install pandas
      run: pip install pandas

    - name: Download latest artifacts from all workflows
      run: |
        set -e
        mkdir csvs

        WORKFLOWS=(
          "Run Twitter Agent"
          "Run TikTok LLM Script Every 6 Hours"
          "Scrape TikTok Hashtags"
          "run reddit agent"
          "Run YouTube Agent"
          "Run Google Trends Agent"
        )
        REPO="${{ github.repository }}"

        for WF in "${WORKFLOWS[@]}"; do
          echo "Fetching artifacts for workflow: $WF"

          # 1) Query the workflow list, then extract its .id via jq
          WF_ID=$(gh api \
            -H "Authorization: token $GH_TOKEN" \
            "/repos/$REPO/actions/workflows" | \
            jq -r ".workflows[] | select(.name==\"$WF\") | .id")

          # 2) Get the most recent successful run ID
          RUN_ID=$(gh api \
            -H "Authorization: token $GH_TOKEN" \
            "/repos/$REPO/actions/workflows/$WF_ID/runs?status=success&per_page=1" | \
            jq -r ".workflow_runs[0].id")

          # 3) Get that runâ€™s artifact ID
          ART_ID=$(gh api \
            -H "Authorization: token $GH_TOKEN" \
            "/repos/$REPO/actions/runs/$RUN_ID/artifacts" | \
            jq -r ".artifacts[0].id")

          # 4) Download & unzip the artifact
          gh api \
            -H "Authorization: token $GH_TOKEN" \
            "/repos/$REPO/actions/artifacts/$ART_ID/zip" \
            -o "csvs/${WF// /_}.zip"

          unzip -o "csvs/${WF// /_}.zip" -d csvs/
        done


    - name: Merge CSVs
      run: |
        python3 - << 'EOF'
        import glob, pandas as pd
        files = glob.glob("csvs/*.csv")
        df = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)
        df.to_csv("consolidated_output.csv", index=False)
        EOF

    - name: Upload consolidated CSV
      uses: actions/upload-artifact@v4
      with:
        name: consolidated-output
        path: consolidated_output.csv

    - name: Set up Python for Caption Agent
      uses: actions/setup-python@v4
      with:
        python-version: "3.10"

    - name: Install project dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Generate captions from consolidated_output.csv
      run: |
        python caption_agent.py --input consolidated_output.csv --n 12

    - name: Upload captions artifact
      uses: actions/upload-artifact@v4
      with:
        name: captions_consolidated_output
        path: captions_consolidated_output.csv
