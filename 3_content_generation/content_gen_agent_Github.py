#!/usr/bin/env python
"""
Run Abacus.AI ContentGen, poll until it finishes, download *all* attachments
(including those nested in segments) and write them to disk so GitHub Actions
can archive them.
"""
from __future__ import annotations
import argparse, base64, json, os, sys, time, requests
from datetime import datetime
from pathlib import Path
from typing import List
from abacusai import ApiClient

# â”€â”€â”€ Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _env(k: str) -> str:
    try: return os.environ[k]
    except KeyError: sys.exit(f"âŒ  Missing env-var {k}")

API_KEY, DEPLOYMENT_ID, DEPLOYMENT_TOKEN = (
    _env("ABACUSAPIKEY"),
    _env("DEPLOYMENT_ID"),
    _env("DEPLOYMENT_TOKEN"),
)
client = ApiClient(API_KEY)

# â”€â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _all_attachments(payload: dict) -> List[dict]:
    """Return every attachment dict found anywhere in the payload."""
    atts: List[dict] = payload.get("attachments", [])
    for seg in payload.get("segments", []):
        atts.extend(seg.get("attachments", []))
    return atts

def _save_bytes(data: bytes, fname: str) -> None:
    Path(fname).write_bytes(data); print(f"ðŸ“¥  Saved {fname}")

def _download(att: dict) -> None:
    """Save an attachment dict (any source) to disk."""
    fname = att["filename"]

    # â”€â”€ A) Inline content (base64 or plain) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if "content" in att:
        content = att["content"]
        if isinstance(content, str) and content.startswith("data:"):
            content = content.split(",", 1)[1]
        try:
            data = base64.b64decode(content)
        except Exception:                   # not base64 â†’ assume utf-8 text
            data = content.encode()
        _save_bytes(data, fname)
        return

    # â”€â”€ B) Stored in Abacus object store (attachmentId / attachment_id) â”€â”€â”€â”€
    if "attachment_id" in att or "attachmentId" in att:
        aid = att.get("attachment_id") or att.get("attachmentId")
        resp = client.download_agent_attachment(   # HTTPResponse object
            deployment_id=DEPLOYMENT_ID,
            attachment_id=aid,
        )
        data = resp.read()         # <<â€“â€“ KEY FIX: read bytes from stream
        _save_bytes(data, fname)
        return

    # â”€â”€ C) Signed URL (rare) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if "url" in att:
        r = requests.get(att["url"], timeout=60)
        r.raise_for_status()
        _save_bytes(r.content, fname)
        return

    print(f"âš ï¸  Unknown attachment format for {fname}")


# â”€â”€â”€ Main runner â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_workflow(topic: str, ceiling=12*60) -> List[str]:
    print(f"ðŸš€  Executing ContentGen for topic: {topic}")
    result = client.execute_agent(
        deployment_token=DEPLOYMENT_TOKEN,
        deployment_id=DEPLOYMENT_ID,
        keyword_arguments={"topic": topic},
    )

    # save first payload for debugging
    Path("debug_response.json").write_text(json.dumps(result, indent=2))
    conv_id = result.get("deploymentConversationId") or \
              result.get("deployment_conversation_id")
    poll_int = 20
    deadline = time.time() + ceiling

    while time.time() < deadline:
        if _all_attachments(result): break
        if "Image generation complete!" in result.get("streamed_data", ""): break
        time.sleep(poll_int)
        result = client.execute_agent(
            deployment_token=DEPLOYMENT_TOKEN,
            deployment_id=DEPLOYMENT_ID,
            keyword_arguments={"topic": topic},
            deployment_conversation_id=conv_id,
        )
    else:
        sys.exit(f"âŒ  Workflow did not finish within {ceiling//60} min")

    files = []
    for att in _all_attachments(result):
        try:
            _download(att); files.append(att["filename"])
        except Exception as e:
            print(f"âš ï¸  Could not download {att['filename']}: {e}")

    # summary index
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    summary = Path(f"content_summary_{topic.replace(' ','_')}.md")
    summary.write_text(
        "# ContentGen Summary â€“ {}\n\n**Generated at:** {}\n\n## Files\n{}\n\n---\n*Generated by Abacus.AI ContentGen*"
        .format(topic, ts, "\n".join(f"- {f}" for f in sorted(files)))
    )
    files.append(summary.name)
    return files

# â”€â”€â”€ CLI entry-point â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    p = argparse.ArgumentParser(); p.add_argument("--topic", required=True)
    saved = run_workflow(p.parse_args().topic.strip())
    print("\nâœ¨  Done! Files captured:")
    for f in saved: print(f"   â€¢ {f}")
